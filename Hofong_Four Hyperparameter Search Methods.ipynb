{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045e0c99",
   "metadata": {},
   "source": [
    "## Hyperparameter Search Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5417ff8e",
   "metadata": {},
   "source": [
    "When modeling, the hyperparameters of the model have a certain impact on the accuracy, and setting and adjusting the value of the hyperparameters is often called parameter tuning.\n",
    "\n",
    "In practice, parameter tuning often relies on humans to set the adjustment range, and then use the machine to search within the hyperparameter range. This article will demonstrate the four basic hyperparameter search methods supported in sklearn:\n",
    "\n",
    "- GridSearch\n",
    "- RandomizedSearch\n",
    "- HalvingGridSearch\n",
    "- HalvingRandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb8c2615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import KFold   #For K-fold cross validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08fbd49",
   "metadata": {},
   "source": [
    "### Initial Model\n",
    "As an accuracy comparison, we initially use random forests to train the initial model and calculate the accuracy on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8237f350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8289473684210527"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrive the data\n",
    "df = pd.read_csv('heart.csv')\n",
    "X = df.drop(columns=['output'])\n",
    "y = df['output']\n",
    "\n",
    "# data split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, stratify=y)\n",
    "\n",
    "# data training & accuracy\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "clf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f409dda",
   "metadata": {},
   "source": [
    "### GridSearch\n",
    "GridSearch is a relatively basic hyperparameter search method. The principle is to traverse all hyperparameter combinations in the calculation process, and then search for the optimal result.\n",
    "\n",
    "As shown in the code below, we search for 4 hyperparameters, and the search space is 5 * 3 * 2 * 3 = 90 sets of hyperparameters. For each set of hyperparameters, 5-fold cross-validation needs to be calculated, which requires 450 training times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "869e62fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 90 candidates, totalling 450 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8552631578947368"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "parameters = {\n",
    "    'max_depth': [2,4,5,6,7],\n",
    "    'min_samples_leaf': [1,2,3],\n",
    "    'min_weight_fraction_leaf': [0, 0.1],\n",
    "    'min_impurity_decrease': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Fitting 5 folds for each of 90 candidates, totalling 450 fits\n",
    "clf = GridSearchCV(\n",
    "    RandomForestClassifier(random_state=0),\n",
    "    parameters, refit=True, verbose=1,\n",
    ")\n",
    "clf.fit(x_train, y_train)\n",
    "clf.best_estimator_.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafc5fd7",
   "metadata": {},
   "source": [
    "### HalvingGridSearch\n",
    "HalvingGridSearch is very similar to GridSearch, but in the process of iteration, there is an operation of halving the parameter combination.\n",
    "\n",
    "**At first, all hyperparameter combinations are used, but the least data is used, the optimal hyperparameters are filtered, and the data is added and then filtered.**\\\n",
    "\n",
    "The idea of HalvingGridSearch is very similar to that of hyperband, but the most simple implementation. Use a small amount of data to filter the hyperparameter combinations first, then use more data to verify the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a8f97e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': None, 'min_samples_split': 5, 'n_estimators': 9}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"min_samples_split\": [5, 10]}\n",
    "search = HalvingGridSearchCV(clf, param_grid, resource='n_estimators',\n",
    "                             max_resources=10,\n",
    "                             random_state=0).fit(X, y)\n",
    "search.best_params_  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b501a",
   "metadata": {},
   "source": [
    "### HalvingRandomSearch\n",
    "HalvingRandomSearch and HalvingGridSearch are similar in that they gradually increase samples and reduce hyperparameter combinations. But each time a hyperparameter combination is generated, it is randomly selected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c8291917",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_samples_split': 3, 'n_estimators': 9}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from scipy.stats import randint\n",
    "import numpy as np\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "np.random.seed(0)\n",
    "\n",
    "param_distributions = {\"max_depth\": [3, None],\n",
    "                       \"min_samples_split\": randint(2, 11)}\n",
    "search = HalvingRandomSearchCV(clf, param_distributions,\n",
    "                               resource='n_estimators',\n",
    "                               max_resources=10,\n",
    "                               random_state=0).fit(X, y)\n",
    "search.best_params_  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a3e548",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "HalvingGridSearch and HalvingRandomSearch are more suitable for use when the amount of data is relatively large, which can improve the training speed. GridSearch and HalvingGridSearch will give better results if computing resources are sufficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde0f7f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
